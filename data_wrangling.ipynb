{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "nVxpNzuJXCY1",
        "RkIwrnDeAC9h",
        "HuJ4idPSFHAn",
        "pqq_1LrFU2WH"
      ],
      "mount_file_id": "12nx6q6z5ezu9cFD_oe0smE5bianCXjM9",
      "authorship_tag": "ABX9TyNOz6MwLWwc8ywtQ5RGvzeP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data wrangling over excel files [library testing]\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sV7rqaCK_8gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Requirements"
      ],
      "metadata": {
        "id": "nVxpNzuJXCY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars==0.15.8\n",
        "!pip install numpy==1.21.6\n",
        "!pip install pandas==1.3.5\n",
        "!pip install xlrd==1.2.0"
      ],
      "metadata": {
        "id": "TNHaUwwR_XUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import xlrd as xls\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "eHaH_2wu_Qk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### **A prior implementation**: descriptions are included"
      ],
      "metadata": {
        "id": "RkIwrnDeAC9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/data_income/existencias-animales.xlsx\"\n",
        "file = \"/content/data_income/actividad-principal-region.xlsx\"\n",
        "file = \"/content/data_income/existencias-colmenas.xlsx\""
      ],
      "metadata": {
        "id": "_fJWqKscHnhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ini = lambda x, xs: [index+1 for (name, pibot, index) in zip(xs, [\"><\"]+xs, range(len(xs))) if name == pibot]\n",
        "get_indexes = lambda x, xs: [i for (y, i) in zip(xs, range(len(xs))) if x == y]\n",
        "del_duplicate = lambda xs: [name for (name, pibot) in zip(xs, [\"><\"]+xs) if name != pibot]\n",
        "## Filling up empty space within the row\n",
        "filling_data = lambda xs: [ xs[i-1] if ( xs[i]==\"\" and i>0 ) else xs[i] for i in range(len(xs)) ]"
      ],
      "metadata": {
        "id": "Q8YpDuIEgyqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining indexes for sectoring data content"
      ],
      "metadata": {
        "id": "2TbM42va3NKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "work_book = xls.open_workbook(file)\n",
        "work_book = work_book.sheet_by_index(0)\n",
        "\n",
        "column = 1\n",
        "\n",
        "array_col = work_book.col_values(column)[1:]\n",
        "#array_col = del_duplicate(array_col)\n",
        "\n",
        "*a,ini,fin = get_indexes(\"\", array_col)\n",
        "\n",
        "## Filling up empty space within the row\n",
        "array_col = filling_data(array_col)\n",
        "\n",
        "## Keeping range that it cotains data\n",
        "array_col = array_col[ini: fin]\n",
        "print(array_col)"
      ],
      "metadata": {
        "id": "RcaoulQtH_5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting columns as arrays\n",
        "Sizing data of the columns\n",
        "Data normalization\n",
        "Storing arrays into fields\n",
        "\n",
        "This process will finish when there are no more columns with data"
      ],
      "metadata": {
        "id": "Ab-BkzLN-yNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = np.array(array_col)\n",
        "\n",
        "column=2\n",
        "while True:\n",
        "  try:\n",
        "    array_col = work_book.col_values(column)[1:]\n",
        "    #array_col = del_duplicate(array_col)\n",
        "    \n",
        "    ## Filling up empty space within the row\n",
        "    array_col = filling_data(array_col)\n",
        "\n",
        "    array_col = array_col[ini:fin]\n",
        "    column+=1\n",
        "\n",
        "    ## Data normalization\n",
        "    array_col = np.char.lower(array_col)\n",
        "    array_col = np.char.replace(array_col, \" \", \"_\")\n",
        "\n",
        "    #print(array_col)\n",
        "    fields = np.row_stack((fields, array_col))\n",
        "  except:\n",
        "    print(\"Ending column\")\n",
        "    break\n",
        "print(fields)"
      ],
      "metadata": {
        "id": "w-I_w9djqheZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing rows with lots of null values to get title for the dataframe"
      ],
      "metadata": {
        "id": "es8wkMZe46Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_to_dataframe = np.transpose(fields)\n",
        "\n",
        "pos = 0\n",
        "normal_long = len(array_to_dataframe[pos])\n",
        "\n",
        "while True:\n",
        "  titles = array_to_dataframe[pos]\n",
        "  out_arr = np.char.count(titles, sub ='', start=1, end=1)\n",
        "  actual_long = np.sum(out_arr)\n",
        "  if not len(out_arr) == actual_long :\n",
        "    array_to_dataframe = array_to_dataframe[1:]\n",
        "  else:\n",
        "    break\n",
        "\n",
        "titles = np.char.lower(titles)\n",
        "titles = np.char.replace(titles, \" \", \"_\")\n",
        "\n",
        "for i in range(len(titles)):\n",
        "  titles[i] = titles[i] +\"_\"+ str(i)\n",
        "\n",
        "print(titles)"
      ],
      "metadata": {
        "id": "zcLgd29nl3dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing the datafram"
      ],
      "metadata": {
        "id": "6it8Ti8O5PaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_polar = pl.from_numpy(data=array_to_dataframe, columns=list(titles),)\n",
        "pl.from_numpy\n",
        "df_polar = df_polar[1:]\n",
        "print(df_polar)\n",
        "\n",
        "file = file.replace(\"_income\",\"_outcome\")\n",
        "df_polar.write_csv(file.split('.')[0]+'.csv')\n"
      ],
      "metadata": {
        "id": "KaU46lQn43G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### **Class CsvFileItem [version 1]**: Object-oriented programming for Encapsulation and abstraction"
      ],
      "metadata": {
        "id": "HuJ4idPSFHAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CsvFileItem:\n",
        "  \n",
        "  get_ini = lambda x, xs: [index+1 for (name, pibot, index) in zip(xs, [\"><\"]+xs, range(len(xs))) if name == pibot == '']\n",
        "  get_indexes = lambda x, xs: [i for (y, i) in zip(xs, range(len(xs))) if x == y]\n",
        "  del_duplicate = lambda xs: [name for (name, pibot) in zip(xs, [\"><\"]+xs) if name != pibot]\n",
        "  ## Filling up empty space within the row\n",
        "  filling_data = lambda xs: [ xs[i-1] if ( xs[i]==\"\" and i>0 ) else xs[i] for i in range(len(xs)) ]\n",
        "\n",
        "  def __init__(self, path_file) -> None:\n",
        "    self.path_file = path_file\n",
        "    self.name_file = path_file.split('/')[-1]\n",
        "    self.column=1\n",
        "    self.dataframe=1\n",
        "  \n",
        "  def get_column_workbook(self, column):\n",
        "    work_book = xls.open_workbook(self.path_file)\n",
        "    work_book = work_book.sheet_by_index(0)\n",
        "    array_col = work_book.col_values(column)[1:]\n",
        "\n",
        "    return array_col\n",
        "\n",
        "  def get_action_margin(self):\n",
        "    array_col = self.get_column_workbook(1)\n",
        "    *a,ini,fin = CsvFileItem.get_indexes(\"\", array_col)\n",
        "    return ini, fin\n",
        "\n",
        "  def filling_empty_cells(self, array_col):\n",
        "    ## Filling up empty space within the row\n",
        "    array_col = CsvFileItem.filling_data(array_col)\n",
        "    return array_col\n",
        "\n",
        "  def data_normalization(self, array_col):\n",
        "    ## Data normalization\n",
        "    array_col = np.char.lower(array_col)\n",
        "    array_col = np.char.strip(array_col)\n",
        "    array_col = np.char.replace(array_col, \" \", \"_\")\n",
        "    array_col = np.char.replace(array_col, \".\", \"\")\n",
        "    array_col = np.char.replace(array_col, \",\", \"\")\n",
        "    return array_col\n",
        "  \n",
        "\n",
        "  def get_columns_with_data(self):\n",
        "    ini, fin = self.get_action_margin()\n",
        "    array_col = self.get_column_workbook(self.column)\n",
        "    array_col = self.filling_empty_cells(array_col)\n",
        "    array_col = self.filling_empty_cells(array_col)\n",
        "    array_col = self.filling_empty_cells(array_col)\n",
        "    array_col = array_col[ini:fin]\n",
        "\n",
        "\n",
        "    column_collection = np.array(array_col)\n",
        "\n",
        "    self.column+=1\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "        array_col = self.get_column_workbook(self.column)\n",
        "        array_col = self.filling_empty_cells(array_col)\n",
        "        array_col = self.filling_empty_cells(array_col)\n",
        "        array_col = self.filling_empty_cells(array_col)\n",
        "        array_col = array_col[ini:fin]\n",
        "\n",
        "        self.column+=1\n",
        "\n",
        "        array_col = self.data_normalization(array_col)\n",
        "\n",
        "        column_collection = np.row_stack((column_collection, array_col))\n",
        "      except:\n",
        "        # \"Ending columns\"\n",
        "        break\n",
        "    return column_collection\n",
        " \n",
        "  def create_folder(self):\n",
        "    path_outcome = self.path_file.split(\"/\")[:-2] + ['data_outcome/']\n",
        "    path_outcome = \"/\".join(path_outcome)\n",
        "    \n",
        "    # Check whether the specified path exists or not\n",
        "    isExist = os.path.exists(path_outcome)\n",
        "    if not isExist:\n",
        "      # Create a new directory because it does not exist\n",
        "      os.makedirs(path_outcome)\n",
        "    \n",
        "    return path_outcome\n",
        "\n",
        " \n",
        "  def get_titles_dataframe(self):\n",
        "    array_to_dataframe = np.transpose(self.get_columns_with_data())\n",
        "    ## Going over rows\n",
        "    titles=[]\n",
        "    pos = 0\n",
        "    normal_long = len(array_to_dataframe[pos])\n",
        "\n",
        "    while True:\n",
        "      titles = array_to_dataframe[pos]\n",
        "      out_arr = np.char.count(titles, sub ='', start=1, end=1)\n",
        "      actual_long = np.sum(out_arr)\n",
        "      out_arr = out_arr.tolist()\n",
        "      if not len(out_arr) == actual_long :\n",
        "        array_to_dataframe = array_to_dataframe[1:]\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    #titles = self.data_normalization(titles)\n",
        "    titles = titles.tolist()\n",
        "\n",
        "    #if it would have many occurences, just in time \n",
        "    if len(titles) >0 :\n",
        "      titles = [ name+\"_\"+str(i) for (name,i) in zip(titles, range(len(titles)))  ]\n",
        "\n",
        "    return titles, array_to_dataframe\n",
        "\n",
        "\n",
        "  def save_dataframe_csv(self):\n",
        "    titles, array_to_dataframe = self.get_titles_dataframe()\n",
        "\n",
        "    df_polar = pl.from_numpy(data=array_to_dataframe, columns=list(titles),)\n",
        "    \n",
        "    df_polar = df_polar[1:]\n",
        "    self.dataframe = df_polar\n",
        "\n",
        "    path_outcome = self.create_folder()\n",
        "    path_outcome = path_outcome + self.name_file.split('.')[0]+'.csv'\n",
        "    print(path_outcome)\n",
        "\n",
        "    df_polar.write_csv(path_outcome)\n"
      ],
      "metadata": {
        "id": "bFBIWs06Hejj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data wragling over INE's files.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FiOV2th1WBoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Class FIleReader** : In order to provide data to Array_xl class"
      ],
      "metadata": {
        "id": "pqq_1LrFU2WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "class FileReader:\n",
        "  def __init__(self, path):\n",
        "    self.path = path\n",
        "    self.list_files = []\n",
        "  \n",
        "  def collect_files(self):\n",
        "    # Get the list of all files and directories\n",
        "    self.list_files = os.listdir(self.path)\n",
        "    self.list_files = [ self.path +'/'+ x for x in self.list_files ]\n",
        "\n",
        "  def show_files(self):\n",
        "    for x in range(len(self.list_files)):\n",
        "      print(x+1, \"  \", self.list_files[x])"
      ],
      "metadata": {
        "id": "2Q2lohlmFkUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Class Array_xl** : data wrangling over INE's files."
      ],
      "metadata": {
        "id": "Mxs9AT-Hd8UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import xlrd as xls\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Array_xl:\n",
        "  work_book = \"\"\n",
        "  xl_array = np.array([])\n",
        "  url_bookincome = \"\"\n",
        "  url_bookoutside = \"\"\n",
        "\n",
        "  def __init__(self, url_bookincome, url_bookoutside, index=0):\n",
        "    self.url_bookincome = url_bookincome\n",
        "    self.url_bookoutside = url_bookoutside\n",
        "    self.work_book = xls.open_workbook(url_bookincome)\n",
        "    self.work_book = self.work_book.sheet_by_index(index)\n",
        "    self.to_ndimention_xls()\n",
        "    self.create_folder_outcome()\n",
        "\n",
        "  def to_ndimention_xls(self):\n",
        "    \"\"\" Proccessing data and giving Numpy array format: source excel file \"\"\"\n",
        "\n",
        "    rack_book = np.array(['']*self.work_book.ncols, dtype='<U32')\n",
        "    for i in range(self.work_book.nrows):\n",
        "      rack_book = np.vstack( ( rack_book, np.array(self.work_book.row_values(i), dtype='<U32') ) )    \n",
        "    self.xl_array = rack_book\n",
        "  \n",
        "  def show_work_book(self):\n",
        "    \"\"\" show work_rows' rows \"\"\"\n",
        "    for i in work_book.get_rows():\n",
        "      print(i)\n",
        "  \n",
        "  def show_array_excel(self):\n",
        "    \"\"\" show array excel's rows \"\"\"\n",
        "    if len(self.xl_array):\n",
        "      for i in self.xl_array:\n",
        "        print(i)\n",
        "  \n",
        "  def get_ncols(self):\n",
        "    _, b = self.xl_array.shape\n",
        "    return b\n",
        "  def get_nrows(self):\n",
        "    a, _ = self.xl_array.shape\n",
        "    return a\n",
        "\n",
        "  def extending_values_blanckspaces(self):\n",
        "    \"\"\" extextending values toward blank cells: source xl_array\"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    rack_rows = np.array([False]*ncols)\n",
        "    for i in range(nrows):\n",
        "      array_row = self.xl_array[i]\n",
        "      for index in range(len(array_row)):##going by columns\n",
        "        if array_row[index] == '' and index > 0:\n",
        "          self.xl_array[i, index] = self.xl_array[i, index-1]\n",
        "\n",
        "  def remove_empty_rows(self):\n",
        "    \"\"\" Removing empty rows: source xl_array \"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    c = 0\n",
        "    while c < nrows:\n",
        "      nempty = self.xl_array[c].tolist().count('')\n",
        "      if nempty == ncols:\n",
        "        self.xl_array = np.delete( self.xl_array, c, 0)\n",
        "        nrows = self.get_nrows()\n",
        "      else:\n",
        "        c+=1\n",
        "\n",
        "  def remove_empty_cols(self):\n",
        "    \"\"\" removing empty columns: source xl_array\"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    \n",
        "    for i in range(1, ncols):\n",
        "      nempty = self.xl_array[:, i-1:i]\n",
        "      nempty = np.transpose(nempty).tolist()[0].count('')\n",
        "      if float(nempty/nrows) >= 0.75 :\n",
        "        self.xl_array = self.xl_array[:, i:]\n",
        "  \n",
        "  def is_empty_col(self, col:int):\n",
        "    \"\"\" Verifying if this column is empty: source xl_array\"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    if col < ncols:\n",
        "      col+=1\n",
        "      nempty = self.xl_array[:, col-1:col]\n",
        "      nempty = np.transpose(nempty).tolist()[0].count('')\n",
        "      if nempty == nrows :\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "    else:\n",
        "      print(\"Col out of range\")\n",
        "\n",
        "  def is_empty_row(self,row:int):\n",
        "    \"\"\"## Verifying if this row is empty: source self.xl_array\"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    if row < nrows:\n",
        "      nempty = self.xl_array[row].tolist().count('')\n",
        "      if nempty == ncols:\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "    else:\n",
        "      print(\"Row out of range\")\n",
        "    \n",
        "\n",
        "\n",
        "  def remove_head_comments(self):\n",
        "    \"\"\" Removing comments head 1. By a row with contente between before and after blank line 2 and if it would be the first and unique column with data: source self.xl_array \"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    empty = False\n",
        "    row_remove=[]\n",
        "    index=0\n",
        "    while index < int(nrows*0.3):\n",
        "      if self.is_empty_row(index):\n",
        "        row_remove.append(index)\n",
        "      index+=1\n",
        "\n",
        "    if len(row_remove):\n",
        "      row_remove = np.arange(row_remove[0],row_remove[-1])\n",
        "      self.xl_array = np.delete(self.xl_array, row_remove, axis=0)\n",
        "\n",
        "\n",
        "  def extending_values_blanckspaces_col(self):\n",
        "    \"\"\" Filling blank spaces in columns\"\"\"\n",
        "    self.xl_array = np.transpose(self.xl_array)\n",
        "    self.extending_values_blanckspaces()\n",
        "    self.xl_array = np.transpose(self.xl_array)\n",
        "\n",
        "  def remove_bottom_comments(self):\n",
        "    \"\"\" Removing comments bottom 2. \n",
        "    By couting from last row to up and verifying \n",
        "    if it would be the first and unique column with data: source self.xl_array \"\"\"\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    empty = False\n",
        "    row_remove=[]\n",
        "    for i in range(1, int(nrows*0.3)): \n",
        "      # raging up to 30% to the array seeking for comment section\n",
        "      if not self.is_empty_row(-i):\n",
        "        row_remove.append(-i)\n",
        "      else:\n",
        "        row_remove.append(-i)\n",
        "        empty = True\n",
        "        break\n",
        "    if len(row_remove) and empty:\n",
        "      self.xl_array = np.delete( self.xl_array, row_remove, axis = 0)\n",
        "    else:\n",
        "      print(\"There is no comment section apparently >\", row_remove)\n",
        "\n",
        "\n",
        "  def create_folder_outcome(self):\n",
        "    \"\"\" Check whether the specified path exists or not. Create a new directory because it does not exist\"\"\"\n",
        "    isExist = os.path.exists(self.url_bookoutside)\n",
        "    if not isExist:\n",
        "      os.makedirs(self.url_bookoutside)\n",
        "  \n",
        "  def get_titles_dataframe(self):\n",
        "    nrows, ncols = self.get_nrows(), self.get_ncols()\n",
        "    #print(list(map(chr, range(65, 91))))\n",
        "    titles = np.array([i for i in range(ncols)] ).astype(str)\n",
        "    return titles\n",
        "\n",
        "\n",
        "  def default_dataframe_csv(self):\n",
        "    \"\"\" Establishing a correlation of integer numbers as titles for dataframe \"\"\"\n",
        "    titles = self.get_titles_dataframe()\n",
        "\n",
        "    df_polar = pl.from_numpy(data=self.xl_array, columns=titles.tolist(),)\n",
        "    self.dataframe = df_polar\n",
        "    print(df_polar)\n",
        "\n",
        "    df_polar.write_csv(self.url_bookoutside+\"/\"+self.url_bookincome.split('/')[-1].split('.')[0]+'.csv')\n",
        "  \n",
        "  def there_are_repeated(self, titles:list):\n",
        "    ini = len(titles)\n",
        "    fin = len( list(set(titles)) )\n",
        "    if ini == fin:\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "\n",
        "  def asign_correlative_row(self, titles:list):\n",
        "    for i in range(len(titles)):\n",
        "      titles[i] = titles[i]+\"_\"+str(i)\n",
        "    return titles\n",
        "\n",
        "  def custom_dataframe_csv(self, row=None, titles=None):\n",
        "    \"\"\" row:int or titles:list Establishing a certain row within self.xl_array as titles for dataframe \"\"\"\n",
        "    if titles == None or row == None:\n",
        "      if row != None:\n",
        "        row = int(row)\n",
        "        titles = self.xl_array[row].astype(str).tolist()\n",
        "        data = self.xl_array[row+1:]\n",
        "      else:\n",
        "        data = self.xl_array\n",
        "        titles = np.array(titles).astype(str).tolist()\n",
        "        \n",
        "      if self.there_are_repeated(titles):\n",
        "        titles = self.asign_correlative_row(titles)\n",
        "      \n",
        "      df_polar = pl.from_numpy(data=data, columns=titles)\n",
        "      self.dataframe = df_polar\n",
        "      print(df_polar)\n",
        "      df_polar.write_csv(self.url_bookoutside+\"/\"+self.url_bookincome.split('/')[-1].split('.')[0]+'.csv')\n",
        "    else:\n",
        "      print(\"Passed arguments is a must or both are not valid at the same time\")\n",
        "\n",
        "  def data_wrangling(self):\n",
        "    self.remove_head_comments()\n",
        "    self.remove_bottom_comments()\n",
        "\n",
        "    self.remove_empty_cols()\n",
        "    self.remove_empty_rows()\n",
        "\n",
        "    self.extending_values_blanckspaces()\n",
        "    self.extending_values_blanckspaces_col()\n",
        "  \n",
        "  def data_normalization(self):\n",
        "    \"\"\"It will swap: uppercase to lowercase, \n",
        "    blanckspace to underscore, and other\"\"\"\n",
        "    self.xl_array = np.char.lower(self.xl_array)\n",
        "    self.xl_array = np.char.strip(self.xl_array)\n",
        "    self.xl_array = np.char.replace(self.xl_array, \"-\", \"\")\n",
        "    self.xl_array = np.char.replace(self.xl_array, \"  \", \" \")\n",
        "    self.xl_array = np.char.replace(self.xl_array, \" \", \"_\")\n",
        "    ##self.xl_array = np.char.replace(self.xl_array, \".\", \"\")\n",
        "    ##self.xl_array = np.char.replace(self.xl_array, \",\", \"\")\n",
        "  \n"
      ],
      "metadata": {
        "id": "uBsKOlvf1pC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Main class**"
      ],
      "metadata": {
        "id": "ZCByg2J5UTG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = FileReader('/content/data_income')\n",
        "files.collect_files()\n",
        "files.show_files()"
      ],
      "metadata": {
        "id": "d0YKFvzWaoNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for url_file in files.list_files:\n",
        "  print( url_file)\n",
        "  array_xl = Array_xl(url_file, '/content/data_outcome_ine_cl')\n",
        "\n",
        "  array_xl.data_wrangling()\n",
        "  array_xl.data_normalization()\n",
        "  array_xl.default_dataframe_csv()\n",
        "  #array_xl.custom_dataframe_csv(1)\n",
        "  print(array_xl.xl_array.shape)\n",
        "  "
      ],
      "metadata": {
        "id": "jpGy9J-zgPXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( files.list_files[10])\n",
        "url_file = files.list_files[10]\n",
        "array_xl = Array_xl(url_file, '/content/data_outcome_ine_cl')\n",
        "\n",
        "print(array_xl.xl_array.shape)\n",
        "array_xl.data_wrangling()\n",
        "print(array_xl.xl_array.shape)\n",
        "\n",
        "array_xl.default_dataframe_csv()\n",
        "array_xl.data_normalization()\n",
        "array_xl.custom_dataframe_csv(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print( files.list_files[11])\n",
        "url_file = files.list_files[11]\n",
        "array_xl = Array_xl(url_file, '/content/data_outcome_ine_cl')\n",
        "\n",
        "print(array_xl.xl_array.shape)\n",
        "array_xl.data_wrangling()\n",
        "print(array_xl.xl_array.shape)\n",
        "\n",
        "array_xl.default_dataframe_csv()\n",
        "array_xl.data_normalization()\n",
        "array_xl.custom_dataframe_csv(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print( files.list_files[12])\n",
        "url_file = files.list_files[12]\n",
        "array_xl = Array_xl(url_file, '/content/data_outcome_ine_cl')\n",
        "\n",
        "print(array_xl.xl_array.shape)\n",
        "array_xl.data_wrangling()\n",
        "print(array_xl.xl_array.shape)\n",
        "\n",
        "array_xl.default_dataframe_csv()\n",
        "array_xl.data_normalization()\n",
        "array_xl.custom_dataframe_csv(1)"
      ],
      "metadata": {
        "id": "0Qj88Zb35ZZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}